---
title: SST Guidelines using AWS
parent: Infrastructure
layout: default
nav_order: 1
---

# SST Guidelines using AWS

This guide outlines the use of [SST](https://sst.dev/) with the goal of explaining how to deploy a NestJS backend and a React frontend on AWS using SST.

## Requirements

- AWS Account: You must have access to an AWS account, preferably with Admin permissions.

- IAM user should be configured with the necessary permissions to create secret keys.

- Windows:
  If using Windows, you need to install [WSL](https://learn.microsoft.com/en-us/windows/wsl/install).
  Throughout the entire process, commands must be run within the WSL environment.

- Install [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)

- Repository Variables: 
  If you are using Bitbucket Pipelines, you need to configure the repository variables. Go to Repository variables in Bitbucket and set up the following variables with the secret checkbox enabled:

  AWS_ACCESS_KEY_ID  
  AWS_SECRET_ACCESS_KEY  
  AWS_REGION  

In this example, neither Route53 nor SSL certificates are configured. These can be set up manually after finishing the process. (If anyone tries it and it works, please include information about it in this guidelines.)

## Recommendations for the process

> âœ… Make sure to always use the same package manager that the project uses (npm/pnpm/yarn) to run the necessary commands in order to avoid inconsistencies.

> âœ… At the start of working with the backend or frontend project, delete the node_modules and dist folders, then run npm/pnpm/yarn install followed by npm/pnpm/yarn run build.

> âœ… It is recommended to perform this action using the latest Node LTS version in the project.

> ðŸ’¡ TIP: [SST console](https://sst.dev/docs/console/): SST offers an interface to view the resources; this step is optional.

> ðŸš¨ **WARNING**: In this process, **DON'T manually add or delete resources from the AWS console** to avoid losing the SST state.

## Init SST

Start by opening the project to be deployed, creating a new branch, and navigating to the project's root directory.

- INIT SST: Run the command to start SST:

```bash
 npx sst@latest init
```
    At this moment, some SST folders and files will be autogenerated in the project:

    .sst <= SST dependencies, automatically added to .gitignore

    sst-env.d.ts <= Interface that describes the environment variables

    sst.config.ts <= This is where the deploy script will be placed

- UPDATE tsconfig.json: For the backend, it is necessary to modify the tsconfig.json so that the build works by adding:

```ts
"include": ["src/**/*", "test/**/*", "sst-env.d.ts"]
```

- SCRIPTS: Add these scripts to the package.json; they will be used to specify the deploy according to the environment (stage):

```json
"scripts": {
    "deploy:production": "sst deploy --stage production",
    "deploy:staging": "sst deploy --stage staging",
}
```

- Health endpoint: Include a GET health endpoint in backend side.
```typescript
@Get('/health')
  health() {
    return { status: 'ok' };
  }
```

## NestJS Backend sst.config.ts

This file is automatically generated when running the sst init command. An example of how to complete its content is included.

To deploy the backend, in these guidelines we will use the following SST resources:

- [Service](https://sst.dev/docs/component/aws/service/)
Use [Elastic Container Service](https://aws.amazon.com/ecs/) together with [AWS Fargate](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/AWS_Fargate.html) and [Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing/) to host the backend.

- [Postgres](https://sst.dev/docs/component/aws/postgres/)
Use [AWS RDS Postgres](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_PostgreSQL.html)

- [Secret Manager](https://www.pulumi.com/registry/packages/aws/api-docs/secretsmanager/) to store environment variables using [AWS Secret Manager](https://aws.amazon.com/secrets-manager/)

```ts
/// <reference path="./.sst/platform/config.d.ts" />

export enum StageEnum {
  PROD = 'production',
  TEST = 'staging',
}

export default $config({
  app(input) {
    const stage = input?.stage as StageEnum;
    return {
      name: 'project-name-backend',
      removal: stage === StageEnum.PROD ? 'retain' : 'remove',
      protect: ['production'].includes(input?.stage),
      home: 'aws',
    };
  },
  async run() {
    const environment = $app.stage;
    const projectName = 'spotlink';

    // VPC
    const vpcName = `vpc`;
    const vpc = new sst.aws.Vpc(vpcName, { bastion: true });

    // RDS
    const rdsName = `rds`;
    const rds = new sst.aws.Postgres(rdsName, {
      vpc,
      username: `${projectName}Admin`,
      password:
        environment === StageEnum.PROD
          ? process.env.DATABASE_PASSWORD_PRODUCTION
          : process.env.DATABASE_PASSWORD_STAGING,
    });
    const DATABASE_URL = rds.username.apply(username =>
      rds.password.apply(password =>
        rds.host.apply(host =>
          rds.port.apply(port =>
            rds.database.apply(database => 
              `postgresql://${username}:${password}@${host}:${port}/${database}`
            )
          )
        )
      )
    );
    
    // SECRET MANAGER
    const secretManagerName = `${projectName}--${environment}--secrets-manager`;
    const secret = new aws.secretsmanager.Secret(secretManagerName);

    // SECRET VERSION
    const secretVersionName = `${projectName}--${environment}--secret-version`;
    const secretVersion = new aws.secretsmanager.SecretVersion(secretVersionName, {
      secretId: secret.id.apply(id =>id),
      secretString: DATABASE_URL.apply(databaseUrl => JSON.stringify({
        DATABASE_URL: databaseUrl,
        SENDGRID_API_KEY: process.env.SENDGRID_API_KEY,
        NODE_ENV: process.env.NODE_ENV,
        EMAIL_FROM: process.env.EMAIL_FROM,
        PORT: process.env.PORT,
        JWT_SECRET: process.env.JWT_SECRET,
        JWT_EXPIRES_IN: process.env.JWT_EXPIRES_IN,
        JWT_SECRET_ADMIN: process.env.JWT_SECRET_ADMIN,
        JWT_EXPIRES_IN_ADMIN: process.env.JWT_EXPIRES_IN_ADMIN,
        JWT_RESET_PASSWORD_SECRET: process.env.JWT_RESET_PASSWORD_SECRET,
        JWT_RESET_PASSWORD_EXPIRES_IN: process.env.JWT_RESET_PASSWORD_EXPIRES_IN,
        AWS_REGION: process.env.AWS_REGION,
        SWAGGER_USER: process.env.SWAGGER_USER,
        SWAGGER_PASSWORD: process.env.SWAGGER_PASSWORD,
        FRONTEND_URL: process.env.FRONTEND_URL,
        BACKOFFICE_FRONTEND_URL: process.env.BACKOFFICE_FRONTEND_URL,
      })),
    });

    // ECS
    const clusterName = `ecs-cluster`;
    const cluster = new sst.aws.Cluster(clusterName, { vpc });
    console.log('Cluster', cluster);

    const serviceName = `${projectName}-backend-${environment}-ecs-service`;
    const service = new sst.aws.Service(serviceName, {
      cluster,
      link: [rds, secret], // Associate secret manager and rds 
      permissions: [
        {
          effect: 'allow',
          actions: [
            'secretsmanager:GetSecretValue',
            'secretsmanager:CreateSecret',
            'secretsmanager:DescribeSecret',
          ],
          resources: ['*'],
        },
      ],
      ssm: {
        DATABASE_URL: secret.arn.apply(arn => `${arn}:DATABASE_URL::`),
        SENDGRID_API_KEY: secret.arn.apply(arn => `${arn}:SENDGRID_API_KEY::`),
        NODE_ENV: secret.arn.apply(arn => `${arn}:NODE_ENV::`),
        EMAIL_FROM: secret.arn.apply(arn => `${arn}:EMAIL_FROM::`),
        PORT: secret.arn.apply(arn => `${arn}:PORT::`),
        JWT_SECRET: secret.arn.apply(arn => `${arn}:JWT_SECRET::`),
        JWT_EXPIRES_IN: secret.arn.apply(arn => `${arn}:JWT_EXPIRES_IN::`),
        JWT_SECRET_ADMIN: secret.arn.apply(arn => `${arn}:JWT_SECRET_ADMIN::`),
        JWT_EXPIRES_IN_ADMIN: secret.arn.apply(arn => `${arn}:JWT_EXPIRES_IN_ADMIN::`),
        JWT_RESET_PASSWORD_SECRET: secret.arn.apply(arn => `${arn}:JWT_RESET_PASSWORD_SECRET::`),
        JWT_RESET_PASSWORD_EXPIRES_IN: secret.arn.apply(arn => `${arn}:JWT_RESET_PASSWORD_EXPIRES_IN::`),
        AWS_REGION: secret.arn.apply(arn => `${arn}:AWS_REGION::`),
        SWAGGER_USER: secret.arn.apply(arn => `${arn}:SWAGGER_USER::`),
        SWAGGER_PASSWORD: secret.arn.apply(arn => `${arn}:SWAGGER_PASSWORD::`),
        FRONTEND_URL: secret.arn.apply(arn => `${arn}:FRONTEND_URL::`),
        BACKOFFICE_FRONTEND_URL: secret.arn.apply(arn => `${arn}:BACKOFFICE_FRONTEND_URL::`),
      },
      loadBalancer: {
        // domain: "example.com",
        ports: [
          { listen: '80/http', forward: '3000/http' },
          // { listen: '443/https', forward: '3000/http' }, // If the project is configured with Route53 using a custom domain and has an SSL certificate, it is correct to send this option, also providing the domain.
        ],
        health: {
          '3000/http': {
            path: '/health',
            interval: '30 seconds',
            timeout: '5 seconds',
          },
        },
      },
    });
    service.url.apply(data => console.log(`SERVICE_URL: ${data}`));
  },
});

```
In the output SERVICE_URL, you will be able to get access to the Backend URL.

## React Frontend sst.config.ts

This file is automatically generated when running the sst init command. An example of how to complete its content is included.

To deploy the React frontend, in these guidelines we will use the following SST resources:

- [StaticSite](https://sst.dev/docs/component/aws/static-site/)
Use [S3](https://aws.amazon.com/s3/) together with [Cloudfront](https://aws.amazon.com/cloudfront/) to host the frontend.

```ts
/// <reference path="./.sst/platform/config.d.ts" />

export default $config({
  app(input) {
    return {
      name: "project-name-frontend",
      removal: input?.stage === "production" ? "retain" : "remove",
      protect: ["production"].includes(input?.stage),
      home: "aws",
    };
  },
  async run() {
    const environment = $app.stage;
    const projectName = 'project-name';

    const staticName = `${projectName}-${environment}`;
    const staticSite = new sst.aws.StaticSite(staticName, {
      environment: {
        VITE_API_BASE_URL: process.env.VITE_API_BASE_URL
      },
      build: {
        command: "pnpm run build",
        output: "dist"
      },
    });
    staticSite.url.apply(url => console.log('STATIC_SITE_URL', `${url}`));
  },
});
```
In the output STATIC_SITE_URL, you will be able to get access to the Frontend URL on CloudFront.

## Configure Bitbucket Pipelines

It is necessary to configure Bitbucket pipelines in order to perform the deploy and have the AWS repository variables configured in bitbucket as detailed previously.

Add the bitbucket-pipelines.yml file in the root directory of the project.

Below is a sample file as a guide, but it may vary depending on the project:

### Bitbucket Pipelines with pnpm

```yml
image: node:22.14.0

definitions:
  caches:
    pnpm: $BITBUCKET_CLONE_DIR/.pnpm-store

pipelines:
  branches:
    master:
      - step:
          name: SST Deploy to AWS
          size: 2x
          caches:
            - node
            - pnpm
          deployment: production
          script:
            - echo "Deploying to stage production"
            - corepack enable
            - corepack prepare pnpm@latest-10 --activate
            - pnpm install --frozen-lockfile
            - pnpm run deploy:production
          services:
            - docker

    staging:
      - step:
          name: SST Deploy to AWS
          size: 2x
          caches:
            - node
            - pnpm
          deployment: staging
          script:
            - echo "Deploying to stage staging"
            - corepack enable
            - corepack prepare pnpm@latest-10 --activate
            - pnpm install --frozen-lockfile
            - pnpm run deploy:staging
          services:
            - docker

  pull-requests:
    '**':
      - step:
          name: Build and test
          script:
            - npm install --global corepack@latest
            - corepack enable
            - corepack prepare pnpm@latest-10 --activate
            - pnpm install
            - pnpm run build
          caches:
            - pnpm

```

### Bitbucket Pipelines with npm

```yml
image: node:22.15.0

definitions:
pipelines:
  branches:
    master:
      - step:
          name: SST Deploy to AWS
          size: 2x
          caches:
            - node
          deployment: production
          script:
            - echo "Deploying to stage production"
            - npm run deploy:production
          services:
            - docker

    staging:
      - step:
          name: SST Deploy to AWS
          size: 2x
          caches:
            - node
          deployment: staging
          script:
            - echo "Deploying to stage staging"
            - npm run deploy:staging
          services:
            - docker

  pull-requests:
    '**':
      - step:
          name: Build and test
          script:
            - npm ci
            - npm run lint
            - npm run build
          caches:
            - node

```

## Configure Dockerfile (only for backend)

It is necessary to add a Dockerfile in the root of the backend project. Below is a sample Dockerfile as a guide, but it may vary depending on the project:

```dockerfile
FROM node:22-alpine

# Intall OpenSSL y dependencies
RUN apk update && apk add --no-cache openssl

# RUN as root
RUN apk add dumb-init
# Use the node user from the image (instead of the root user)
USER node
# Create app directory
WORKDIR /home/node

# Copy application dependency manifests to the container image.
# A wildcard is used to ensure copying both package.json AND package-lock.json (when available).
# Copying this first prevents re-running npm install on every code change.
COPY --chown=node:node package*.json ./
# Install app dependencies using the `npm ci` command instead of `npm install`
RUN npm ci
# Bundle app source
COPY --chown=node:node . .

# We need this because SST generates type definitions that are being used by the app
COPY sst-env.d.ts . 

# Run the build command which creates the production bundle
RUN npx prisma generate

RUN npm run build

RUN chmod 777 ./docker-script.sh

# Start the server using the production build
CMD ./docker-script.sh

```

## SST Deploy

When everything is ready to deploy, first run the command for staging. Once the whole process is complete in that environment, move on to production. 

One step at a time.

```bash
npm run deploy:staging

```

```bash
npm run deploy:production

```

## SST Commands - Just in case

If at any point in the process you need to delete everything created in that project, you can run this command in the root of the project specifying the environment; it will delete absolutely everything generated by SST in that project and environment.

```bash
 npx sst remove --stage staging
```

If you need to sync the AWS resources with your local machine due to some error, there is a command that performs synchronization between both environments so that SST knows which AWS resources exist.

```bash
 npx sst refresh --stage staging
```

## Finally

- Finally, check in the AWS account that the required services are running correctly.
- Share the necessary access credentials with the team.
- Make a test by making some change in the repo and deploy using Bitbucket and the pipelines.
- Enjoy the new environments!ðŸ˜Ž 
